{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_Neuroevolution_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kredenac/AutomatedReasoningCDCL/blob/master/Baseline_Model/Baseline_Neuroevolution_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfJ-fn_XLnLU",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DoSLvx2LdSl",
        "colab_type": "code",
        "outputId": "e36a52c1-bece-4046-ad10-5f54dd9ab9b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfoTzVEoMfV6",
        "colab_type": "code",
        "outputId": "ef57eb30-7115-4cd6-fa83-dacc6f016329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPool2D, Add, Activation, Flatten, Concatenate, Dense, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam  \n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import LeakyReLU, concatenate\n",
        "from keras.layers.advanced_activations import ReLU\n",
        "from keras.initializers import glorot_normal\n",
        "import keras.backend as K\n",
        "from keras.models import load_model  # Save model params\n",
        "\n",
        "def extract_dataset(path):\n",
        "  \"\"\"\n",
        "  extract DoubledMNIST dataset\n",
        "  Argument: path to .zip file with the dataset\n",
        "  Return value: x_train, y_train, x_test, y_test lists of numpy arrays \n",
        "  \n",
        "  (DoubledMNIST dataset: train size 120k images 56x56, test size 20k images 56x56)\n",
        "  \"\"\"\n",
        "  # import libraries\n",
        "  import os                     # for basic os operations\n",
        "  from zipfile import ZipFile \n",
        "  from skimage import io\n",
        "  import shutil\n",
        "  \n",
        "  if not path.endswith('.zip'):\n",
        "    raise ValueError(\"Error: path is not '.zip' file\")\n",
        "  \n",
        "  archive = ZipFile(path, 'r')  # extract\n",
        "  archive.extractall('./DoubledMNIST')\n",
        "  archive.close()\n",
        "  del archive\n",
        "  \n",
        "  x_train = []\n",
        "  y_train = []\n",
        "  x_test = []\n",
        "  y_test = []\n",
        "  \n",
        "  for file in os.listdir('./DoubledMNIST/train'):\n",
        "    img = io.imread(os.path.join('./DoubledMNIST/train', file))\n",
        "    x_train.append(np.array(img))\n",
        "    y_train.append(int(file.split('_')[1]))\n",
        "  \n",
        "  for file in os.listdir('./DoubledMNIST/test'):\n",
        "    img = io.imread(os.path.join('./DoubledMNIST/test', file))\n",
        "    x_test.append(np.array(img))\n",
        "    y_test.append(int(file.split('_')[1]))\n",
        "    \n",
        "  shutil.rmtree('./DoubledMNIST')\n",
        "  return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bKQ505PMxBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mnist(doubled=0, ntrain=None, ntest=None):\n",
        "    \"\"\"\n",
        "    doubled==0 -> load MNIST; doubled==1-> load DoubledMNIST\n",
        "    ntrain - number of train samples\n",
        "    ntest - number of test samples\n",
        "    \"\"\"\n",
        "\n",
        "    from keras.utils import to_categorical\n",
        "    import numpy as np\n",
        "\n",
        "    if doubled==0:\n",
        "        # load mnist\n",
        "        from keras.datasets import mnist\n",
        "\n",
        "        (_x_train, _y_train), (_x_test, _y_test) = mnist.load_data()\n",
        "        if ntrain==None:\n",
        "            ntrain = _x_train.shape[0]\n",
        "        if ntest==None:\n",
        "            ntest = _x_test.shape[0]\n",
        "        assert ntrain<=_x_train.shape[0] and ntest<=_x_test.shape[0]\n",
        "    else:\n",
        "        # load doubled mnist\n",
        "        _x_train, _y_train, _x_test, _y_test = extract_dataset('./drive/My Drive/ni_sem/DoubledMNIST.zip')\n",
        "\n",
        "    # Prepare images\n",
        "    box_size = _x_train.shape[1]\n",
        "    y_train = to_categorical(_y_train)[:ntrain]\n",
        "    y_test = to_categorical(_y_test)[:ntest]\n",
        "    x_train = np.array(_x_train).astype('float32')[:ntrain]\n",
        "    x_train /= 255\n",
        "    x_train = np.reshape(x_train,[-1, box_size, box_size, 1])\n",
        "    x_test = np.array(_x_test).astype('float32')[:ntest]\n",
        "    x_test /= 255\n",
        "    x_test = np.reshape(x_test, [-1, box_size, box_size, 1])\n",
        "    return x_train, y_train, x_test, y_test, box_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5K7U7oOg4_4",
        "colab_type": "code",
        "outputId": "7b40a7d7-0de6-4123-b6c5-6d9842409d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "%%time\n",
        "x_train, y_train, x_test, y_test, box_size = load_mnist(doubled=0, ntrain=10000, ntest=1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "CPU times: user 315 ms, sys: 148 ms, total: 463 ms\n",
            "Wall time: 1.71 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8PNO4_WwR-E",
        "colab_type": "code",
        "outputId": "a20784de-118d-4ae1-ba2b-c95faba9b6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 28, 28, 1), (10000, 10), (1000, 28, 28, 1), (1000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA_twWHcP-71",
        "colab_type": "code",
        "outputId": "76cc389b-5e2b-40b4-ba14-1cbe787de3e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "from matplotlib import pyplot as plt  # smal demonstration\n",
        "\n",
        "plt.imshow(x_test[19].reshape((x_test.shape[1], x_test.shape[2])))\n",
        "plt.show()\n",
        "\n",
        "print(y_test[19])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndiAJwg4kQdiBJAg7kMT/A8+T6g7j+JKWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uungJ3ZiczL",
        "colab_type": "text"
      },
      "source": [
        "# CNN tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HDESDezifHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "FILTERS = np.array([32, 48, 64])\n",
        "sampleIndividual = [1, 0, 1,   1, 1, 0, 1, 0, 0,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
        "\n",
        "# sampleIndividual = [1, 0, 1,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi klasicna CNN\n",
        "# stage1 examples\n",
        "# sampleIndividual = [1, 0, 0,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; trojka eliminisana\n",
        "# sampleIndividual = [0, 1, 0,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; dvojka eliminisana\n",
        "# sampleIndividual = [0, 0, 1,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; jedinica eliminisana\n",
        "# sampleIndividual = [0, 0, 0,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; samo jedna konv.\n",
        "# stage2 examples\n",
        "# sampleIndividual = [1, 0, 1,   0, 0, 0, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi 0->3->4->5\n",
        "# sampleIndividual = [1, 0, 1,   0, 1, 0, 0, 0, 0,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi 0->1->3->5\n",
        "# sampleIndividual = [1, 0, 1,   1, 1, 0, 1, 0, 0,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; 0->1->2,3,4->5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbp0WjNmifCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __create_indices(num_nodes):\n",
        "  \"\"\"\n",
        "  num_nodes - number of nodes per each stage\n",
        "\n",
        "  Calculate bits indices (startindex, length) for each stage \n",
        "  \"\"\"\n",
        "  l =  0                              # genome length\n",
        "  bits_indices, i = np.empty((0,2),dtype = np.int32), 0 \n",
        "  for Ks in num_nodes:\n",
        "    length = Ks * (Ks - 1)\n",
        "    bits_indices = np.vstack([bits_indices,[i, i + int(0.5 * length)]])\n",
        "    i += int(0.5 * length)\n",
        "    l += length\n",
        "  l = int(0.5 * l)\n",
        "  return bits_indices, l\n",
        "\n",
        "def CNN_build(stages, num_nodes, n_filters, individual, box_size, n_classes, verbose=0):\n",
        "  \"\"\"\n",
        "  stages - array of stage names\n",
        "  num_nodes - number of conv nodes per each stage\n",
        "  n_filters - number of filters per stage\n",
        "  individual - binary list representing individual architecture\n",
        "  box_size - expect input images like (box_size, box_size)\n",
        "  n_classes - number of output clasees\n",
        "\n",
        "  Build CNN architecture from the given list\n",
        "  \"\"\"\n",
        "\n",
        "  L = len(individual)\n",
        "  bits_indices, _L= __create_indices(num_nodes)\n",
        "  assert(L==_L)  # small check of the input individual connections info\n",
        "\n",
        "  if(verbose):\n",
        "    print('Starting network building..')\n",
        "  image_shape = (box_size, box_size, 1) \n",
        "  x_input = Input(shape=image_shape)  \n",
        "  previous = None # output from previous stage (initially input of CNN)\n",
        "  # Build stage by stage\n",
        "  for i, (s, Ks, n_filter) in enumerate(zip(stages, num_nodes, n_filters)):\n",
        "    if i==0:\n",
        "      previous = x_input\n",
        "    if(verbose):\n",
        "        print('\\nBuild layer', s, ':', Ks, 'nodes,', n_filter, 'filters.')\n",
        "    stage_indices = individual[bits_indices[i][0]:bits_indices[i][1]]                  # connection indices for current stage nodes; ex. [1, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
        "    stage_indexes = np.split(range(int(Ks*(Ks-1)/2)),np.cumsum(range(Ks - 1)))[1:]     # connection indexes for current stage nodes; ex. [array([0]), array([1, 2]), array([3, 4, 5]), array([6, 7, 8, 9])]\n",
        "    stage_nodes = []                                                                   # nodes in a stage; ex. [vs1_1, vs1_2, vs1_3] (0, 4 are dummy)\n",
        "    to_him = list(np.zeros(Ks))                                                              # number of nodes to which i-th node points to\n",
        "    from_him = list(np.zeros(Ks))  \n",
        "    if(verbose):                                                          # number of nodes from i-th node to others\n",
        "        print('Stage indices:', stage_indices)\n",
        "        print('Stage indexes:', stage_indexes)\n",
        "\n",
        "    # default stage input node\n",
        "    if(verbose):\n",
        "        print('Building '+'v'+str(s)+'_0')\n",
        "    vs0 = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_0')(previous)  # TODO\n",
        "    if(verbose):\n",
        "        print('Builded '+'v'+str(s)+'_0')\n",
        "\n",
        "    # first node and trivial vs0->vs1\n",
        "    if(verbose):\n",
        "        print('Building '+'v'+str(s)+'_1')\n",
        "    vs1 = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_1')(vs0) \n",
        "    stage_nodes += [vs1]\n",
        "    if(verbose):\n",
        "        print('Builded '+'v'+str(s)+'_1')\n",
        "\n",
        "    for j in range(2, Ks+1):\n",
        "      name = 'v'+str(s)+'_'+str(j)  # name of the current node\n",
        "      if(verbose):\n",
        "        print('Building '+name)\n",
        "      tonode = stage_indices[stage_indexes[j-2][0]:stage_indexes[j-2][-1]+1]  # slice from stage_indices\n",
        "      input = None  # Input to current node\n",
        "      if sum(tonode)==0:  # empty input, connect to vs0\n",
        "        input = vs0\n",
        "      else:  # have some input\n",
        "        for k, connection in enumerate(tonode):\n",
        "          if connection==1:\n",
        "            from_him[k] += 1\n",
        "            to_him[j-1] += 1\n",
        "            if input is None:\n",
        "              input = stage_nodes[k]\n",
        "            else:\n",
        "              input = Add()([input, stage_nodes[k]])\n",
        "      v = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_'+str(j))(input) \n",
        "      stage_nodes += [v]\n",
        "      if(verbose):\n",
        "        print('Builded node '+name)\n",
        "\n",
        "    if(verbose):\n",
        "        print('from_him: ', from_him)\n",
        "        print('to_him: ', to_him)\n",
        "        print('stage_nodes: ', stage_nodes)\n",
        "\n",
        "    if sum(from_him)==sum(to_him)==0:  # only one convolution vs0\n",
        "        previous = MaxPool2D(pool_size=(2,2), padding='same')(vs0)\n",
        "    else:  # have some of the ordinary nodes\n",
        "        if(verbose):\n",
        "            print('Building '+'v'+str(s)+'_'+str(Ks+1))\n",
        "        input = None  # last node no output definitelly\n",
        "        for k in range(len(stage_nodes)):\n",
        "            if from_him[k]==0 and to_him[k]!=0:  # no connections from that node\n",
        "                if(verbose):\n",
        "                    print('Connect to last node node', k, ' ', stage_nodes[k])\n",
        "                if input is None:\n",
        "                    input = stage_nodes[k]\n",
        "                else:\n",
        "                    input = Add()([input, stage_nodes[k]])\n",
        "        vsKs = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_'+str(Ks+1))(input) # defaul stage output node\n",
        "        if(verbose):\n",
        "            print('Builded '+'v'+str(s)+str(Ks+1))\n",
        "        previous = MaxPool2D(pool_size=(2,2), padding='same')(vsKs)\n",
        "  \n",
        "  # Adding FC part of NN\n",
        "  x = Flatten(name='flatten')(previous)                                                                                       \n",
        "  x = Dense(units=32, activation='relu', name='next_to_last')(x)         \n",
        "  x = Dense(units=n_classes, activation='softmax', name='last')(x)\n",
        "\n",
        "  # Creaate Model\n",
        "  model = Model(inputs=x_input, outputs=x, name='individual')\n",
        "  if(verbose):\n",
        "    print('Created Network builded.')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FND-j48Zie1-",
        "colab_type": "code",
        "outputId": "b7bd295e-7858-4fcc-96de-eeff8eb5a9c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "model = CNN_build(STAGES, NUM_NODES, FILTERS, sampleIndividual, box_size, 10, 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3hhN7e_SZwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compile_model(model):\n",
        "  \"\"\"\n",
        "  model - created Keras model\n",
        "\n",
        "  Compile forwarded model, and return it compiled\n",
        "  \"\"\"\n",
        "\n",
        "  model.compile(optimizer=Adam(lr=1e-3), loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmFypCPpShN2",
        "colab_type": "code",
        "outputId": "3bfd6273-034e-4423-84e3-347c3ddb9830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "model = compile_model(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_TzENOzS2vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_model(model):\n",
        "  \"\"\"\n",
        "  model - created Keras model\n",
        "\n",
        "  plot forwarded model architecture\n",
        "  \"\"\"\n",
        "  from keras.utils import plot_model\n",
        "\n",
        "  print('Model summary: ')\n",
        "  model.summary()\n",
        "  plot_model(model, to_file='model.png')\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rA6YX8CTMcF",
        "colab_type": "code",
        "outputId": "8f4c704d-9600-48a3-83ca-4b397879e547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "visualize_model(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model summary: \n",
            "Model: \"individual\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "vs1_0 (Conv2D)                  (None, 28, 28, 32)   320         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "vs1_1 (Conv2D)                  (None, 28, 28, 32)   9248        vs1_0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs1_2 (Conv2D)                  (None, 28, 28, 32)   9248        vs1_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs1_3 (Conv2D)                  (None, 28, 28, 32)   9248        vs1_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs1_4 (Conv2D)                  (None, 28, 28, 32)   9248        vs1_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 32)   0           vs1_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_0 (Conv2D)                  (None, 14, 14, 48)   13872       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "vs2_1 (Conv2D)                  (None, 14, 14, 48)   20784       vs2_0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_2 (Conv2D)                  (None, 14, 14, 48)   20784       vs2_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_3 (Conv2D)                  (None, 14, 14, 48)   20784       vs2_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 14, 14, 48)   0           vs2_2[0][0]                      \n",
            "                                                                 vs2_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_4 (Conv2D)                  (None, 14, 14, 48)   20784       vs2_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 14, 14, 48)   0           add_1[0][0]                      \n",
            "                                                                 vs2_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_5 (Conv2D)                  (None, 14, 14, 48)   20784       add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 48)     0           vs2_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_0 (Conv2D)                  (None, 7, 7, 64)     27712       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "vs3_1 (Conv2D)                  (None, 7, 7, 64)     36928       vs3_0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_2 (Conv2D)                  (None, 7, 7, 64)     36928       vs3_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_3 (Conv2D)                  (None, 7, 7, 64)     36928       vs3_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_4 (Conv2D)                  (None, 7, 7, 64)     36928       vs3_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_5 (Conv2D)                  (None, 7, 7, 64)     36928       vs3_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_6 (Conv2D)                  (None, 7, 7, 64)     36928       vs3_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 64)     0           vs3_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1024)         0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "next_to_last (Dense)            (None, 32)           32800       flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "last (Dense)                    (None, 10)           330         next_to_last[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 437,514\n",
            "Trainable params: 437,514\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAH-z7QeUFqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, x_train, y_train, x_test, y_test, epochs, batch_size, verbose=1, validation_split=0.0, callbacks=[]):\n",
        "    \"\"\"\n",
        "    model - compiled CNN model\n",
        "    x_train - input images\n",
        "    y_train - input labels (one hot encoded)\n",
        "    x_test - test images\n",
        "    y_test - test labels (one hot encoded)\n",
        "    epochs - number of epochs\n",
        "    batch_size - mini batch size of training\n",
        "    verbose - verbose of training\n",
        "    validation_split - data split used for validation\n",
        "\n",
        "    Train forwrded model. Returns (train history, model obtained test accuracy)\n",
        "    \"\"\"\n",
        "    if (epochs == 0):\n",
        "        # for faster testing\n",
        "        # print('only eval, without training')\n",
        "        return None, model.evaluate(x_test, y_test)\n",
        "    # print('training and eval')\n",
        "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_split=validation_split, callbacks=callbacks)\n",
        "    return history, model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv7hRnZHWK9J",
        "colab_type": "code",
        "outputId": "3d378229-c807-4a78-ce76-efe060575857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "history, result = train_model(model, x_train, y_train, x_test, y_test, 1, 1024, 1)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "10000/10000 [==============================] - 9s 911us/step - loss: 2.1881 - acc: 0.1807\n",
            "1000/1000 [==============================] - 0s 275us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8214303073883056, 0.393]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWrFN-yTkW2W",
        "colab_type": "code",
        "outputId": "da590665-7670-4b1a-e453-138053ceac07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8214303073883056, 0.393]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYRxJ53XkYwr",
        "colab_type": "code",
        "outputId": "d3754d90-7533-4a0a-f302-b84fe8c9657b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3c6c050278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKOiF1-tx74y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadWeights(toModel, fromModel, numSameStages, numNodesPerStage):\n",
        "    '''\n",
        "    toModel: keras model for which to load weights\n",
        "    fromModel: keras model from which to load weights\n",
        "    numSameStages: number of first same stages; can be 0, 1, 2, 3; trivial cases 0 and 3\n",
        "    numNodesPerStage: number of nodes per stage; ex. [3,4,5]\n",
        "\n",
        "    You need to call model.compile. This can be done either before or after the model.load_weights \n",
        "    call but must be after the model architecture is specified and before the model.predict call.\n",
        "    returns the model with loaded weights from file\n",
        "\n",
        "    IMPORTANT: toModel and fromModel MUST HAVE exactly the same architecture on first numSameStages! (same indices eqvivalently)\n",
        "    TODO: add critical pool if want more pooling operations in architecture\n",
        "    '''\n",
        "    assert numSameStages<=len(numNodesPerStage)\n",
        "    allflag = (numSameStages==len(numNodesPerStage))  # to load all weights\n",
        "    for i, layer in enumerate(fromModel.layers):\n",
        "        #print(i, layer.name, layer) \n",
        "\n",
        "        layer_name = layer.get_config()['name']\n",
        "        if numSameStages==0:\n",
        "            if not allflag:\n",
        "                break\n",
        "\n",
        "        toModel.layers[i].set_weights(layer.get_weights())\n",
        "\n",
        "        if 'max_pooling' in layer_name:\n",
        "            numSameStages-=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kdgjBhwRq2c",
        "colab_type": "text"
      },
      "source": [
        "# Genetic Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEWPhebDtHe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dimitrijevic kuca kod\n",
        "import numpy as np\n",
        "from random import random, seed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxC3nzA0tajA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "\n",
        "L =  0                              # genome length\n",
        "BITS_INDICES, l_bpi = np.empty((0,2),dtype = np.int32), 0 # to keep track of bits for each stage S\n",
        "for Ks in NUM_NODES:\n",
        "    t = Ks * (Ks - 1)\n",
        "    BITS_INDICES = np.vstack([BITS_INDICES,[l_bpi, l_bpi + int(0.5 * t)]])\n",
        "    l_bpi += int(0.5 * t)\n",
        "    L += t\n",
        "L = int(0.5 * L)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60yF_tVWDKI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINING_EPOCHS = 10 # T\n",
        "BATCH_SIZE = 20\n",
        "TOTAL_BATCHES = x_train.shape[0] // BATCH_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFU56u2otadr",
        "colab_type": "code",
        "outputId": "446669fb-a3c9-431c-b3c2-2159926ae026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(42) # reproducible\n",
        "class Genetic:\n",
        "    def __init__(self, pc, qc, pm, qm, numGen, numInd, geneLength, bitIndices):\n",
        "        ''' \n",
        "        pc: probability of crossover - whether crossover process begins\n",
        "        qc: probability of stages being exchanged - while in crossover process\n",
        "        pm: probability of mutation - whether mutation process begins\n",
        "        qm: probability of a per bit mutation - while in mutation process\n",
        "        numGen: number of generations\n",
        "        numInd: number of individuals\n",
        "        bitIndices: 2d matrix where each row has two columns - first is the index, and second is the length of bits in gene that code each segment\n",
        "        '''\n",
        "        self.pc = pc\n",
        "        self.qc = qc\n",
        "        self.pm = pm\n",
        "        self.qm = qm\n",
        "        self.numGen = numGen\n",
        "        self.currNumGen = 0\n",
        "        self.numInd = numInd\n",
        "        self.geneLength = geneLength\n",
        "        self.bitIndices = bitIndices\n",
        "        self.oldGen = None\n",
        "        self.initFirstGeneration()\n",
        "    \n",
        "    def initFirstGeneration(self):\n",
        "        ''' \n",
        "        initializes the first generation\n",
        "        '''\n",
        "        self.currNumGen = 1\n",
        "        self.currGen = np.random.randint(0, 2, (self.numInd, self.geneLength))\n",
        "\n",
        "    def getCurrentGeneration(self):\n",
        "        return self.currGen\n",
        "\n",
        "    def selection(self, fitness):\n",
        "        '''\n",
        "        returns indices of individuals that survived the selection\n",
        "        '''\n",
        "        npfit = np.array(fitness)\n",
        "        proba = npfit - np.min(npfit) # removes the worst ones\n",
        "        proba = proba / np.sum(proba)\n",
        "\n",
        "        return np.random.choice(self.numInd, replace=True, size=self.numInd, p=proba)\n",
        "\n",
        "    def mutate(self, newGen, indices):\n",
        "        '''\n",
        "        mutates individuals in newGen on positions where indices are 0 (because those individuals didn't mate)\n",
        "        '''\n",
        "        for i, had in enumerate(indices):\n",
        "            if had == 0 and np.random.random() <= pm:\n",
        "                newGen[i] = self.mutateIndividual(self.currGen[i])\n",
        "            else:\n",
        "                newGen[i] = np.copy(self.currGen[i])\n",
        "\n",
        "    def mutateIndividual(self, individual):\n",
        "        '''\n",
        "        returns a new individual by mutating the given one\n",
        "        '''\n",
        "        mut = np.copy(individual)\n",
        "        for i, val in enumerate(mut):\n",
        "            if np.random.random() <= self.qm:\n",
        "                mut[i] = 1 - mut[i]\n",
        "\n",
        "        return mut\n",
        "\n",
        "    def crossover(self, individualA, individualB):\n",
        "        '''\n",
        "        returns two new individuals by performing crossover on two given individuals.\n",
        "        it takes care to only swap the whole segments, and not bits within segments\n",
        "        '''\n",
        "        a = np.copy(individualA)\n",
        "        b = np.copy(individualB)\n",
        "\n",
        "        for segment in self.bitIndices:\n",
        "            if np.random.random() <= qc:\n",
        "                start = segment[0]\n",
        "                end = segment[1]\n",
        "                # print(f'start {start}, end {end}')\n",
        "                # print('a should now have', b[start:end])\n",
        "                # print('b should now have', a[start:end])\n",
        "                tmpa = np.copy(a[start:end])\n",
        "                a[start:end] = b[start:end]\n",
        "                b[start:end] = tmpa\n",
        "\n",
        "        return a, b\n",
        "\n",
        "    def newGeneration(self, fitness, verbose=False):\n",
        "        '''\n",
        "        creates a new generation of individuals by selection, crossover, and mutation \n",
        "        of previous generation. Selection is based on the rulet method\n",
        "\n",
        "        fitness - np array of fitness metrics for all individuals, based on which to construct rulet\n",
        "        '''\n",
        "        self.currNumGen += 1\n",
        "        if self.currNumGen > self.numGen:\n",
        "            raise Exception(f\"currNumGen > numGen, {self.currNumGen} > {self.numGen}\")\n",
        "        newGenIdx = self.selection(fitness)\n",
        "        if verbose:\n",
        "            print(f'survived selection: {newGenIdx}')\n",
        "        newGen = np.zeros((self.numInd, self.geneLength)) # np matrix of new generation\n",
        "        hadCrossoverIdx = np.zeros(self.numInd) # tracks if an individial had a crossover\n",
        "        # print(f'newGen: {newGen}')\n",
        "        assert(len(newGen)%2 == 0)\n",
        "        # for each pair of neighbours, try crossover\n",
        "        for i in range(0, len(newGen), 2):\n",
        "            if np.random.random() <= pc:\n",
        "                newGen[i], newGen[i+1] = self.crossover(self.currGen[newGenIdx[i]], self.currGen[newGenIdx[i+1]])\n",
        "                hadCrossoverIdx[i] = 1\n",
        "                hadCrossoverIdx[i+1] = 1\n",
        "\n",
        "        self.mutate(newGen, hadCrossoverIdx)\n",
        "        \n",
        "        self.oldGen = self.currGen\n",
        "        self.currGen = newGen\n",
        "\n",
        "    def findIndividualsWithSameRoots(self, verbose=False):\n",
        "        '''\n",
        "        for each individual in a new generation finds the indices of individuals in the old generation \n",
        "        which had the same firts n segments\n",
        "\n",
        "        returns a list, where i-th element has a touple (listOfParentsWithSameSegment, numberOfSameSegments)\n",
        "        '''\n",
        "        parentsAndNumSegments = []\n",
        "        for indiv in self.currGen:\n",
        "            parents, numSameSegments = self.hasSameRoots(indiv)\n",
        "            parentsAndNumSegments.append((parents, numSameSegments))\n",
        "            if numSameSegments > 0 and verbose:\n",
        "                print('individual:',indiv)\n",
        "                print(f'has the same {numSameSegments} first segments as:')\n",
        "                print(parents)\n",
        "                print(f'e.g: {self.oldGen[parents[0]]}')\n",
        "\n",
        "        return parentsAndNumSegments\n",
        "\n",
        "\n",
        "    def hasSameRoots(self, individual):\n",
        "        '''\n",
        "        returns indices of individuals from last generations which have the biggest same root as the\n",
        "        given individual, and returns the number of segments which are the same (starting from the first)\n",
        "        '''\n",
        "        for i, segment in reversed(list(enumerate(self.bitIndices))):\n",
        "            nColumns = segment[1]\n",
        "            # print('bools',(self.oldGen[:,:nColumns] == individual[:nColumns]))\n",
        "            # print('oldgen:',self.oldGen)\n",
        "            # print('ind:', individual)\n",
        "            # find rows which have the individual (only look at the part of the colums)\n",
        "            matchedRows = (self.oldGen[:,:nColumns] == individual[:nColumns]).all(axis=1)\n",
        "            sameRootIndividuals = np.where(matchedRows)[0]\n",
        "            if sameRootIndividuals.size > 0:\n",
        "                return sameRootIndividuals, i+1\n",
        "\n",
        "        return np.empty(0), 0\n",
        "\n",
        "pc, pm = 0.2, 0.8\n",
        "qc, qm = 0.3, 0.1\n",
        "geneLength = L\n",
        "numGenerations, numIndividuals = 10, 10 # they take 50 rounds with 20 individuals\n",
        "gen = Genetic(pc, qc, pm, qm, numGenerations, numIndividuals, geneLength, BITS_INDICES)\n",
        "np.mean(gen.getCurrentGeneration())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5105263157894737"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0jKFnXSuzcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gen.findIndividualsWithSameRoots()\n",
        "# gen.newGeneration(np.ones(numIndividuals))\n",
        "# np.mean(gen.getCurrentGeneration())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5onkJV5pZ4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import types\n",
        "params = types.SimpleNamespace()\n",
        "params.pc, params.pm = pc, pm\n",
        "params.qc, params.qm = qc, qm\n",
        "params.geneLength = L\n",
        "params.numGenerations = 2 # 10\n",
        "params.numIndividuals = 4 # 10\n",
        "params.bitIndices = BITS_INDICES\n",
        "params.boxSize = box_size\n",
        "params.numClasses = 10\n",
        "params.stageNames = STAGES\n",
        "params.numFilters = FILTERS\n",
        "params.numNodes = NUM_NODES # num nodes per stage\n",
        "params.xTrain = x_train\n",
        "params.yTrain = y_train\n",
        "params.xTest = x_test\n",
        "params.yTest = y_test\n",
        "params.epochs = 1 # default number of epochs to train in the first generation\n",
        "params.batchSize = 256\n",
        "params.numInheritedStagesToEpochs = { # maps number of inherited stages into \n",
        "                                      # number of needed epochs to train it\n",
        "                                      # all: 0epoch, 1stage: 4epoch, 2stage: 3epoch\n",
        "    0: params.epochs,\n",
        "    1: params.epochs, #- 1,\n",
        "    2: params.epochs, #- 2,\n",
        "    3: 0\n",
        "}\n",
        "assert(params.numIndividuals%2 == 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx7G8lmn0Tso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createModelsFromIndividuals(params, individuals):\n",
        "    '''\n",
        "    params: contains all needed properties (same as in executeGenetic)\n",
        "\n",
        "    returns a list of newly constructed models from given individuals\n",
        "    '''\n",
        "    newNetworks = []\n",
        "    for ind in individuals:\n",
        "        cnn = CNN_build(params.stageNames, params.numNodes, params.numFilters, ind, params.boxSize, params.numClasses, verbose=0)\n",
        "        cnn = compile_model(cnn)\n",
        "        newNetworks.append(cnn)\n",
        "    return newNetworks\n",
        "\n",
        "def inheritWeightsFromOldModels(models, params, parentSegmentTuples, lastGenModels):\n",
        "    '''\n",
        "    tries to inherit weights from last generation for all new models\n",
        "\n",
        "    models: list of new models\n",
        "    params: object containing all needed parameters,\n",
        "    parentSAegmentTuples: list of tuples, each containing list of parents that share segments with individual, and number of shared segments\n",
        "    lastGenModels: list of models of the last generation\n",
        "    '''\n",
        "    modelsWithWeights = []\n",
        "    trainForEpochs = []\n",
        "    i=1\n",
        "    for model, parentAndSegment in zip(models, parentSegmentTuples):\n",
        "        print(\"loading weights:\", end =\" \")\n",
        "        print(f\"#{i}\", end =\" \")\n",
        "        i += 1\n",
        "        parents = parentAndSegment[0] \n",
        "        numSegments = parentAndSegment[1]\n",
        "        epochsToTrain = params.numInheritedStagesToEpochs[numSegments]\n",
        "        trainForEpochs.append(epochsToTrain)\n",
        "        if numSegments > 0:\n",
        "            # parent = parents[0] # TODO this is a list, might take the parent with the best fitness\n",
        "            # loadWeights(model, lastGenModels[parent], numSegments, params.numNodes)\n",
        "            pass\n",
        "        if model is None:\n",
        "            print('\\t\\t\\t\\ MODEL IS NONE!')\n",
        "        modelsWithWeights.append(model)\n",
        "    print()\n",
        "    return modelsWithWeights, trainForEpochs\n",
        "\n",
        "def trainModelsToGetFitness(models, params, verbose, trainForEpochs, lastGenFitness):  # TODO: ukljuci info koga koliko treniras\n",
        "    '''\n",
        "    trains the given models, and returns their fitness - which is accuracy of each model\n",
        "\n",
        "    models: list of models to be trained\n",
        "    params: dict containing all needed params\n",
        "    verbose: whether to print verbose\n",
        "    trainForEpochs: list of numbers of epochs to train each model\n",
        "    lastGenFitness: given after the first iteration and used if a model is the same as in last gen\n",
        "\n",
        "    returns array of fitness for each model\n",
        "    '''\n",
        "    fitness = []\n",
        "    for i, model in enumerate(models):\n",
        "        print(f'starting to train net num: {i}')\n",
        "        if trainForEpochs[i] == 0:\n",
        "            print('\\t\\t\\t\\Skipping training because model is the same as last gen')\n",
        "            fitness.append(lastGenFitness[i])\n",
        "            continue\n",
        "        history, lossAndAcc = train_model(model, params.xTrain, params.yTrain, params.xTest,\n",
        "                    params.yTest, trainForEpochs[i],\n",
        "                    params.batchSize, verbose=verbose, validation_split=0.0)  # all: 0epoch, 1stage: 4epoch, 2stage: 3epoch\n",
        "        fitness.append(lossAndAcc[1])\n",
        "\n",
        "    return np.array(fitness)\n",
        "\n",
        "def executeSelectionWithGeneticAlgorithm(params):\n",
        "    ''' \n",
        "    params contains the following properties:\n",
        "        pc: probability of crossover - whether crossover process begins\n",
        "        qc: probability of stages being exchanged - while in crossover process\n",
        "        pm: probability of mutation - whether mutation process begins\n",
        "        qm: probability of a per bit mutation - while in mutation process\n",
        "        numGen: number of generations\n",
        "        numInd: number of individuals\n",
        "        bitIndices: 2d matrix where each row has two columns - first is the index, and second is the length of bits in gene that code each segment\n",
        "        boxSize: width and height of the input\n",
        "        numClasses: number of output classes\n",
        "        stageNames: list containing names of staegs\n",
        "        numFilters: list containing number of filters per stage\n",
        "        numNodes: number of nodes within each stage\n",
        "        xTrain: training set data\n",
        "        yTrain: training set labels\n",
        "        xTest: test set data\n",
        "        yTest: test set labels\n",
        "\n",
        "        returns individuals in the last generation, index of the best individual, and their fitnesses, and np matrix of all fitnesses\n",
        "    '''\n",
        "    genetic = Genetic(params.pc, params.qc, params.pm, params.qm, params.numGenerations, params.numIndividuals, params.geneLength, params.bitIndices)\n",
        "    oldNetworks = None\n",
        "    allFitnesses = np.zeros((params.numGenerations, params.numIndividuals))\n",
        "    for i in range(params.numGenerations):\n",
        "        # K.clear_session() # prevents slowdown after creating many TF graphs, but\n",
        "        # if this is uncommented, then weights aren't available on models\n",
        "        nthGen = i+1\n",
        "        print(f'\\t\\t\\tStarting generation {nthGen}...')\n",
        "        print(f'Creating models from individuals...')\n",
        "        individuals = genetic.getCurrentGeneration()\n",
        "        newNetworks = createModelsFromIndividuals(params, individuals)\n",
        "        trainForEpochs = np.full(params.numIndividuals, params.epochs, dtype='int32') \n",
        "        if i > 0:\n",
        "            print(f'findIndividualsWithSameRoots...')\n",
        "            parentSegmentTuples = genetic.findIndividualsWithSameRoots()\n",
        "            print(f'inheritWeightsFromOldModels...')\n",
        "            newNetworks, trainForEpochs = inheritWeightsFromOldModels(newNetworks, params, parentSegmentTuples, oldNetworks)\n",
        "        \n",
        "        print(f'Starting trainModelsToGetFitness...')\n",
        "        lastGenFitness = None if i==0 else allFitnesses[i-1]\n",
        "        fitness = trainModelsToGetFitness(newNetworks, params, verbose=True,\n",
        "                                          trainForEpochs=trainForEpochs, lastGenFitness=lastGenFitness)\n",
        "        allFitnesses[i] = fitness\n",
        "        print(f'all fitness: {fitness}')\n",
        "        if i < params.numGenerations - 1:\n",
        "            genetic.newGeneration(fitness=fitness)\n",
        "            oldNetworks = newNetworks\n",
        "\n",
        "    bestIdx = np.argmax(fitness)\n",
        "    print(f'The best individual {individuals[bestIdx]} had fitness (accuracy): {fitness[bestIdx]}')\n",
        "\n",
        "    return individuals, bestIdx, fitness, allFitnesses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdSVY0xOnvKS",
        "colab_type": "text"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THqXfftoHnfM",
        "colab_type": "code",
        "outputId": "3901fd14-91a4-48cc-ce30-e22604594271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "%%time\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Starting trainModelsToGetFitness...\n",
            "starting to train net num: 0\n",
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-036ba494235e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-f75d7b507305>\u001b[0m in \u001b[0;36mexecuteSelectionWithGeneticAlgorithm\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mlastGenFitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mallFitnesses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         fitness = trainModelsToGetFitness(newNetworks, params, verbose=True,\n\u001b[0;32m--> 108\u001b[0;31m                                           trainForEpochs=trainForEpochs, lastGenFitness=lastGenFitness)\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mallFitnesses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'all fitness: {fitness}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-f75d7b507305>\u001b[0m in \u001b[0;36mtrainModelsToGetFitness\u001b[0;34m(models, params, verbose, trainForEpochs, lastGenFitness)\u001b[0m\n\u001b[1;32m     59\u001b[0m         history, lossAndAcc = train_model(model, params.xTrain, params.yTrain, params.xTest,\n\u001b[1;32m     60\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainForEpochs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                     params.batchSize, verbose=verbose, validation_split=0.0)  # all: 0epoch, 1stage: 4epoch, 2stage: 3epoch\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlossAndAcc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-9d2c02af1e7e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, x_train, y_train, x_test, y_test, epochs, batch_size, verbose, validation_split, callbacks)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# print('training and eval')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2959\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 216\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un1PpVzx3tWI",
        "colab_type": "code",
        "outputId": "658ece59-930d-4240-e12c-723489f3220a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "K.clear_session()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.98 ms, sys: 20 µs, total: 4 ms\n",
            "Wall time: 6.65 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhAAN4N9PnlE",
        "colab_type": "code",
        "outputId": "0be3a672-ed87-432e-a9f7-1b7ab9077286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "def plotEvolutionProgress(allFit, takeBestN):\n",
        "    topn = np.zeros((params.numGenerations, takeBestN))\n",
        "    for i, row in enumerate(allFit):\n",
        "        row.sort()\n",
        "        topn[i] = row[-takeBestN:]\n",
        "\n",
        "    for i, col in reversed(list(enumerate(topn.T))):\n",
        "        plt.plot(range(1, params.numGenerations+1), col, label=f'#{takeBestN - i}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "# plotEvolutionProgress(np.random.randn(params.numGenerations, params.numIndividuals), takeBestN = 2)\n",
        "plotEvolutionProgress(allFitnesses, takeBestN = 10)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-362d19bcc2d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# plotEvolutionProgress(np.random.randn(params.numGenerations, params.numIndividuals), takeBestN = 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplotEvolutionProgress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallFitnesses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeBestN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mallFitnesses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-362d19bcc2d6>\u001b[0m in \u001b[0;36mplotEvolutionProgress\u001b[0;34m(allFit, takeBestN)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallFit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtopn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtakeBestN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (4) into shape (10)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs1lDrRlnywQ",
        "colab_type": "text"
      },
      "source": [
        "## Modification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htL82ZwSn1cC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inheritWeightsFromOldModels(models, params, parentSegmentTuples, lastGenModels):\n",
        "    '''\n",
        "    tries to inherit weights from last generation for all new models\n",
        "\n",
        "    models: list of new models\n",
        "    params: object containing all needed parameters,\n",
        "    parentSAegmentTuples: list of tuples, each containing list of parents that share segments with individual, and number of shared segments\n",
        "    lastGenModels: list of models of the last generation\n",
        "    '''\n",
        "    modelsWithWeights = []\n",
        "    trainForEpochs = []\n",
        "    i=1\n",
        "    for model, parentAndSegment in zip(models, parentSegmentTuples):\n",
        "        print(\"loading weights:\", end =\" \")\n",
        "        print(f\"#{i}\", end =\" \")\n",
        "        i += 1\n",
        "        parents = parentAndSegment[0] \n",
        "        numSegments = parentAndSegment[1]\n",
        "        epochsToTrain = params.numInheritedStagesToEpochs[numSegments]\n",
        "        trainForEpochs.append(epochsToTrain)\n",
        "        if numSegments > 0:\n",
        "            parent = parents[0] # TODO this is a list, might take the parent with the best fitness\n",
        "            loadWeights(model, lastGenModels[parent], numSegments, params.numNodes)\n",
        "            # pass\n",
        "        if model is None:\n",
        "            print('\\t\\t\\t\\ MODEL IS NONE!')\n",
        "        modelsWithWeights.append(model)\n",
        "    print()\n",
        "    return modelsWithWeights, trainForEpochs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lipy3OCxoaX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import types\n",
        "params = types.SimpleNamespace()\n",
        "params.pc, params.pm = pc, pm\n",
        "params.qc, params.qm = qc, qm\n",
        "params.geneLength = L\n",
        "params.numGenerations = 2 # 10\n",
        "params.numIndividuals = 4 # 10\n",
        "params.bitIndices = BITS_INDICES\n",
        "params.boxSize = box_size\n",
        "params.numClasses = 10\n",
        "params.stageNames = STAGES\n",
        "params.numFilters = FILTERS\n",
        "params.numNodes = NUM_NODES # num nodes per stage\n",
        "params.xTrain = x_train\n",
        "params.yTrain = y_train\n",
        "params.xTest = x_test\n",
        "params.yTest = y_test\n",
        "params.epochs = 1 # default number of epochs to train in the first generation\n",
        "params.batchSize = 256\n",
        "params.numInheritedStagesToEpochs = { # maps number of inherited stages into \n",
        "                                      # number of needed epochs to train it\n",
        "                                      # all: 0epoch, 1stage: 4epoch, 2stage: 3epoch\n",
        "    0: params.epochs,\n",
        "    1: params.epochs, #- 1,\n",
        "    2: params.epochs, #- 2,\n",
        "    3: 0\n",
        "}\n",
        "assert(params.numIndividuals%2 == 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVHdNEUGn1HP",
        "colab_type": "code",
        "outputId": "14d42655-99ed-4ccf-d6c7-829064fb247b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        }
      },
      "source": [
        "%%time\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Starting trainModelsToGetFitness...\n",
            "starting to train net num: 0\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 6s 583us/step - loss: 1.6132 - acc: 0.4670\n",
            "1000/1000 [==============================] - 2s 2ms/step\n",
            "starting to train net num: 1\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 6s 558us/step - loss: 1.3689 - acc: 0.5180\n",
            "1000/1000 [==============================] - 2s 2ms/step\n",
            "starting to train net num: 2\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 520us/step - loss: 1.2136 - acc: 0.5944\n",
            "1000/1000 [==============================] - 2s 2ms/step\n",
            "starting to train net num: 3\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 6s 553us/step - loss: 1.1312 - acc: 0.6201\n",
            "1000/1000 [==============================] - 2s 2ms/step\n",
            "all fitness: [0.793 0.656 0.812 0.886]\n",
            "newGen: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\t\t\tStarting generation 2...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "inheritWeightsFromOldModels...\n",
            "loading weights: #1 loading weights: #2 loading weights: #3 loading weights: #4 \n",
            "Starting trainModelsToGetFitness...\n",
            "starting to train net num: 0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "starting to train net num: 1\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 7s 673us/step - loss: 1.1983 - acc: 0.5879\n",
            "1000/1000 [==============================] - 2s 2ms/step\n",
            "starting to train net num: 2\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 6s 638us/step - loss: 1.1550 - acc: 0.6227\n",
            "1000/1000 [==============================] - 2s 2ms/step\n",
            "starting to train net num: 3\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 7s 668us/step - loss: 0.9580 - acc: 0.6847\n",
            "1000/1000 [==============================] - 2s 2ms/step\n",
            "all fitness: [0.793 0.822 0.775 0.903]\n",
            "The best individual [0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1.] had fitness (accuracy): 0.903\n",
            "CPU times: user 2min 41s, sys: 2.01 s, total: 2min 43s\n",
            "Wall time: 2min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNd7V9ajqPkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 3)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuXJhy_ieyQ0",
        "colab_type": "text"
      },
      "source": [
        "# Manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaIZak9OZnqx",
        "colab_type": "code",
        "outputId": "48fbf769-f115-47bc-c0b0-16d245912205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "x_train, y_train, x_test, y_test, box_size = load_mnist(doubled=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "CPU times: user 369 ms, sys: 156 ms, total: 525 ms\n",
            "Wall time: 1.72 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwTVIW1He7kO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "FILTERS = np.array([32, 48, 64])\n",
        "sampleIndividual = [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqSY8vpXfM8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN_build(STAGES, NUM_NODES, FILTERS, sampleIndividual, box_size, 10, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAOeVitcfOyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = compile_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_90wxfdfRXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGteF_JxgBak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, verbose=1, mode='min', cooldown=1)\n",
        "estop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRmqrhD9fbnX",
        "colab_type": "code",
        "outputId": "648816a3-c608-4888-a1f8-fd475b0145bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "%%time\n",
        "history, result = train_model(model, x_train, y_train, x_test, y_test, 20, 256, 1, 0.2, [reducelr, estop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 11s 220us/step - loss: 0.4362 - acc: 0.8560 - val_loss: 0.0875 - val_acc: 0.9751\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 9s 186us/step - loss: 0.0686 - acc: 0.9800 - val_loss: 0.0523 - val_acc: 0.9843\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: 0.0453 - acc: 0.9864 - val_loss: 0.0512 - val_acc: 0.9837\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: 0.0369 - acc: 0.9886 - val_loss: 0.0385 - val_acc: 0.9890\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 9s 186us/step - loss: 0.0300 - acc: 0.9906 - val_loss: 0.0313 - val_acc: 0.9904\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 9s 186us/step - loss: 0.0215 - acc: 0.9934 - val_loss: 0.0324 - val_acc: 0.9894\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0268 - val_acc: 0.9924\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0307 - val_acc: 0.9922\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0294 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 8.3924e-04 - acc: 0.9998 - val_loss: 0.0312 - val_acc: 0.9933\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 9s 185us/step - loss: 3.9299e-04 - acc: 0.9999 - val_loss: 0.0314 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 00011: early stopping\n",
            "10000/10000 [==============================] - 1s 97us/step\n",
            "CPU times: user 1min 2s, sys: 17.5 s, total: 1min 20s\n",
            "Wall time: 1min 41s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMYjil9fjP13",
        "colab_type": "code",
        "outputId": "5c1f5aa4-1107-4bd2-e5e1-2a0ca19d9541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8214303073883056, 0.393]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq26Lc0ujT2Y",
        "colab_type": "code",
        "outputId": "19bbfc80-5d34-4af1-ce4b-7a2671f20c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "epochs = history.epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.title('Loss/Val loss curve')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(epochs, loss, color='red', label='training')\n",
        "plt.plot(epochs, val_loss, color='orange', label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-2ec98f4bc73d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss/Val loss curve'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K8N0nlVjZYp",
        "colab_type": "code",
        "outputId": "86feb4c6-2351-4be3-c5b5-989dd4535267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "plt.title('Acc/Val acc curve')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.plot(epochs, acc, color='red', label='training')\n",
        "plt.plot(epochs, val_acc, color='orange', label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-e2eb1a72036d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Acc/Val acc curve'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1NovR1tAF3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO:\n",
        "# K.clear_session(), but model weights need to be saved first, and passed to inherit weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVp4A8xQU-fb",
        "colab_type": "text"
      },
      "source": [
        "# Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZObn4NLVDK0",
        "colab_type": "text"
      },
      "source": [
        "* Google Schoolar Searches: [link](https://scholar.google.com/scholar?hl=sr&as_sdt=0%2C5&q=genetic+cnn+handwritting&btnG=)\n",
        "\n",
        "* Fokus na rad: \n",
        " * .pdf: [link](https://arxiv.org/abs/1703.01513)\n",
        " * github: [link](https://arxiv.org/abs/1703.01513)\n",
        "* Dodatno rad:\n",
        " *  .pdf: [link](https://arxiv.org/pdf/1710.10741.pdf)\n",
        " * Clanak na netu: [link](https://blog.coast.ai/lets-evolve-a-neural-network-with-a-genetic-algorithm-code-included-8809bece164)\n",
        "* Ako sami implementiramo: [link](https://github.com/joeddav/devol/blob/master/devol/devol.py)\n"
      ]
    }
  ]
}